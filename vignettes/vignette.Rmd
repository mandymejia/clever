---
title: "Clever: Using PCA Leverage for Outlier Detection in High-Dimensional Data"
author: "Amanda Mejia & Preya Shah"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{clever}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r}
library(knitr)
opts_chunk$set(cache=TRUE, autodep=TRUE)
```

## Overview

The Clever package implements the PCA leverage outlier detection method for high-dimensional (HD) data, as detailed in this manuscript:

Citation: Mejia, Amanda F., Mary Beth Nebel, Ani Eloyan, Brian Caffo, and Martin A. Lindquist. "PCA leverage: outlier detection for high-dimensional functional magnetic resonance imaging data." Biostatistics 18, no. 3 (2017): 521-536. [paper link](https://academic.oup.com/biostatistics/article/18/3/521/3056185)

In summary, the manuscript proposed a method to detect outlier observations in HD data by drawing on the traditional statistical ideas of PCA, leverage, and outlier detection. While the primary application is for detecting outlying time points in an fMRI scan, the method can also be applied to other forms of HD data, such as gene expression data.



## Method Outline

As input, the algorithm take an __T__ x __V__ matrix, __Y__. In our case, __Y__ represents an fMRI run, where each row of __Y__ is a vectorized volume, and each column represents one timepoint. Next, the algorithm involves the following key steps: 


1. Normalize the __Y__ matrix.

2. Carry out PCA on the normalized Y matrix using singular value decomposition (SVD), in order to obtain the PC score matrix, __U__ (of dimensionality __T__ x __T__)     

3. Retain the first __Q__ rows of the U matrix corresponding to the first __Q__ < __T__ principal components.  We will refer to this submatrix as __Ũ__ (of dimensionality __T__ x __Q__). This is our dimensionality reduction step. _Note_: To choose the model order __Q__, we retain only components with a greater-than-average eigenvalue; however, the user may input their own __Q__ if desired.


4. Now that we can apply outlier detection on __Ũ__. The primary method is _PCA leverage_, though we also propose an alternative called _robust distance_ (see paper for further details). The output of either of these outlier detection methods is a __T__ x __1__ vector representing the "outlyingness" of each time point.  

5. Now that we have our outlyingness vector, we can threshold it to identify the outliers. We choose 3 thresholds, with increasing level of stringency. Our function outputs the outliers associated with all 3 thresholds.  


## Installation

To install the package from GitHub and load it:

```{r, warning = FALSE, message = FALSE}
library(devtools)
devtools::install_github('damondpham/clever')
library(clever)
```


## Tutorial Data
ABIDE is a publicly available resource of neuroimaging and phenotypic information from 1112 subjects consisting of 20 datasets collected at 16 sites (Di Martino and others, 2014). Our simulated dataset is based on resting-state fMRI scans from two subjects collected as part of the ABIDE dataset. The first dataset contains a number of artifacts; the second is relatively artifact-free.
 
## A Simple Example

Here, we will run through a simple example. First let's pull the data, as follows:

```{r, warning = FALSE, message = FALSE}
data(dat1)
data(dat2)
```

The fMRI data for both subjects has already had a brain mask applied has been vectorized to form a $T\times V$ (time by voxels or vertices) data *matrix*.

```{r}
dim(Dat1)
dim(Dat2)
```

We next run clever on both datasets using all possible combinations of parameters.

```{r}
clever.Dat1.mean.lev = clever(Dat1)
clever.Dat1.kurt.lev = clever(Dat1, choosePCs = 'kurtosis')
clever.Dat1.mean.rds = clever(Dat1, method = 'robdist_subset')
clever.Dat1.kurt.rds = clever(Dat1, choosePCs = 'kurtosis', method = 'robdist_subset')
clever.Dat1.mean.rbd = clever(Dat1, method = 'robdist')
clever.Dat1.kurt.rbd = clever(Dat1, choosePCs = 'kurtosis', method = 'robdist')

clever.Dat2.mean.lev = clever(Dat2)
clever.Dat2.kurt.lev = clever(Dat2, choosePCs = 'kurtosis')
clever.Dat2.mean.rds = clever(Dat2, method = 'robdist_subset')
clever.Dat2.kurt.rds = clever(Dat2, choosePCs = 'kurtosis', method = 'robdist_subset')
clever.Dat2.mean.rbd = clever(Dat2, method = 'robdist')
clever.Dat2.kurt.rbd = clever(Dat2, choosePCs = 'kurtosis', method = 'robdist')

clevers.Dat1 = list(clever.Dat1.mean.lev, clever.Dat1.kurt.lev, clever.Dat1.mean.rds, clever.Dat1.kurt.rds, clever.Dat1.mean.rbd, clever.Dat1.kurt.rbd)

clevers.Dat2 = list(clever.Dat2.mean.lev, clever.Dat2.kurt.lev, clever.Dat2.mean.rds, clever.Dat2.kurt.rds, clever.Dat2.mean.rbd, clever.Dat2.kurt.rbd)
```

There were zero-variance voxels in both files, but neither had enough to warrant concern.

Here are the outlier distributions for the first dataset:

```{r fig.height=12, fig.width=8}
library(ggpubr)
library(gridExtra)
theme_set(theme_pubr())

plt_cell = vector('list', length=6)
plt_row = vector('list', length=3)
for(j in 0:2){
  for(i in 1:2){
    plt_cell[[j*2 + i]] = plot(clevers.Dat1[[j*2 + i]], type='n')
  }
  r = c(plt_cell[(j*2+1):(j*2+2)], common.legend=T, legend='bottom', align='hv', ncol=2)
  plt_row[[j + 1]] = do.call(ggarrange, r)
}

grid.arrange(grobs=plt_row, ncol=1)
```

And for the second:

```{r fig.height=12, fig.width=8}
plt_cell = vector('list', length=6)
plt_row = vector('list', length=3)
for(j in 0:2){
  for(i in 1:2){
    plt_cell[[j*2 + i]] = plot(clevers.Dat2[[j*2 + i]], type='n')
  }
  r = c(plt_cell[(j*2+1):(j*2+2)], common.legend=T, legend='bottom', align='hv', ncol=2)
  plt_row[[j + 1]] = do.call(ggarrange, r)
}

grid.arrange(grobs=plt_row, ncol=1)
```

clever consistently identified a couple of outlier time points in the first data set. The second data set might contain a few false positives, but they are inconsistent among the different parameter settings, and of lower magnitude than those of the first dataset. These results are consistent with our prior knowledge of the datasets.
 
We can reconstruct the original fMRI images with the mask used to obtain their vectorized matrix representations.

```{r}
library(oro.nifti)
library(neurobase)
Mask1 = readNIfTI('../data/Dat1_mask.nii.gz') #Pitt_0050048 (full of artifacts)

Matrix_to_VolumeTimeSeries = function(mat, mask){
  t = nrow(mat)
  dims = c(dim(mask), t)
  in.mask = mask > 0
  nif = array(0, dim=dims)
  #Not be enough memory for below line.
  #nif = copyNIfTIHeader(mask, nif, drop=FALSE)
  for(i in 1:t){
    nif[,,,i][in.mask] = mat[i,]
  }
  return(nif)
}

Img1 = Matrix_to_VolumeTimeSeries(Dat1, Mask1)
```

Below, we look at the midsections for time points 20, 75, 110, 150, and 165 in the first data set. 

```{r}
#Wrapper to convert array to NIfTI, then visualize.
Volume_to_NIfTI = function(VolumeTimeSeries, time, mask){
  vol = VolumeTimeSeries[,,,time]
  vol = copyNIfTIHeader(img=mask, arr=vol)
  return(vol)
}

t_med = 
t_high = 
times = c(t_med, t_high)
z = floor(dim(Mask1)[2]/2)
plots = vector(mode='list', length(times))
for(i in 1:length(times)){
  image(Volume_to_NIfTI(Img1, times[i], Mask1), z=z, plane='sagittal', plot.type='single')
}


```

The fourth, t=150, has banding artifacts, whereas the others appear normal and are nearly indistinguishable from one another by eye. This concurs with clever: t=150 was labeled as an outlier in almost all cases, whereas the other time points were not. 